<!DOCTYPE HTML>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Xuan Rao</title>

    <meta name="author" content="Xuan Rao">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr style="padding:0px">
                <td style="padding:0px">
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr style="padding:0px">
                                <td style="padding:2.5%;width:63%;vertical-align:middle">
                                    <p style="text-align:center">
                                        <name>Xuan Rao È•∂Êº©</name>
                                    </p>
                                    <p>Welcome! I am a PhD candidate at <a href="https://www.uestc.edu.cn/">UESTC</a>, where I work on <strong>Spatial Temporal</strong>, <strong>Data Mining</strong>, and <strong>Reinforcement Learning</strong> advised by
                                        <a href="https://scholar.google.com/citations?user=8qdXaOkAAAAJ&hl=en">Shuo Shang</a>.
                                    </p>
                                    <p style="text-align:center">
                                        <a href="raoxuanzzz@gmail.com">Email</a> &nbsp/&nbsp
                                        <a href="data/resume_xuanrao.pdf">CV</a> &nbsp/&nbsp
                                        <a href="https://scholar.google.com/citations?user=j1Ny1WQAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                                        <a href="https://github.com/kevin-xuan/">GitHub</a> &nbsp/&nbsp
                                    </p>
                                </td>
                                <td style="padding:2.5%;width:40%;max-width:40%">
                                    <a href="img/photo.png"><img style="width:100%;max-width:100%" alt="profile photo" src="img/photo.png" class="hoverZoomLink"></a>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>Research</heading>
                                    <p>
                                        My research interests lie in Spatial Temporal and Reinforcement Learning. In particular, I am interested in mining spatial temporal data and robot learning. This includes Traffic Flow Prediction, Next POI recommendation, Reinforcement Learning, and other
                                        related deep learning topics.
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>

                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <img src='img/Graph-Flashback.png' width="160">
                                    </div>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2304.04227">
                                        <papertitle>MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models</papertitle>
                                    </a>
                                    <br>
                                    <strong>Deyao Zhu*</strong>,
                                    <a href="https://junchen14.github.io/">Jun Chen*</a>,
                                    <a href="https://xiaoqian-shen.github.io/">Xiaoqian Shen</a>,
                                    <a href="https://xiangli.ac.cn/">Xiang Li</a>,
                                    <a href="http://www.mohamed-elhoseiny.com/">Mohamed Elhoseiny</a>
                                    <br>
                                    <em>Preprint</em>
                                    <br>
                                    <a href="https://arxiv.org/abs/2304.10592">arXiv</a> /
                                    <a href="https://github.com/Vision-CAIR/MiniGPT-4">code</a> /
                                    <a href="https://drive.google.com/file/d/1a4zLvaiDBr-36pasffmgpvH5P7CKmpze/view?usp=share_link">model</a> /
                                    <a href="https://drive.google.com/file/d/1nJXhoEcy3KTExr17I7BXqY5Y9Lx_-n-9/view?usp=share_link">dataset</a> /
                                    <a href="https://minigpt-4.github.io/">website</a> /
                                    <a href="https://huggingface.co/spaces/Vision-CAIR/minigpt4">demo</a> /
                                    <a href="https://youtu.be/__tftoxpBAw">video</a>
                                    <p></p>
                                    <p>
                                        MiniGPT-4 shows that the secret behind the next-level vision-language-ability of GPT-4 can be simply a more powerful LLM. By aligning open-sourced vision and advanced language models together, MiniGPT-4 reproduces many GPT-4's vision-related demo.
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <img src='img/FOGS.png' width="160">
                                    </div>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2306.00450">
                                        <papertitle>Exploring Open-Vocabulary Semantic Segmentation without Human Labels</papertitle>
                                    </a>
                                    <br>
                                    <a href="https://junchen14.github.io/">Jun Chen</a>,
                                    <strong>Deyao Zhu</strong>,
                                    <a href="https://guochengqian.github.io/">Guochen Qian</a>,
                                    <a href="https://www.bernardghanem.com/">Bernard Ghanem</a>, Zhicheng Yan, Chenchen Zhu, Fanyi Xiao,
                                    <a href="http://www.mohamed-elhoseiny.com/">Mohamed Elhoseiny</a>, Sean Chang Culatana
                                    <br>
                                    <em>Preprint</em>
                                    <br>
                                    <a href="https://arxiv.org/pdf/2306.00450.pdf">arXiv</a>
                                    <p></p>
                                    <p>
                                        ZeroSeg,a novel method that leverages the existing pretrained vision-language(VL) model to train open-vocabulary zero-shot semantic segmentation models
                                    </p>
                                </td>
                            </tr>



                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <img src='img/RSP.png' width="160">
                                    </div>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2301.12876">
                                        <papertitle>Guiding Online Reinforcement Learning with Action-Free Offline Pretraining</papertitle>
                                    </a>
                                    <br>
                                    <strong>Deyao Zhu</strong>,
                                    <a href="https://wangyuhuix.github.io/">Yuhui Wang</a>,
                                    <a href="https://people.idsia.ch/~juergen/">J√ºrgen Schmidhuber</a>,
                                    <a href="http://www.mohamed-elhoseiny.com/">Mohamed Elhoseiny</a>
                                    <br>
                                    <em>Preprint</em>
                                    <br>
                                    <a href="https://arxiv.org/abs/2301.12876">arXiv</a> /
                                    <a href="https://github.com/Vision-CAIR/AF-Guide">code</a>
                                    <p></p>
                                    <p>
                                        Extract knowledge from datasets without action labels to help online reinforcement learning by pretraining an Action-Free Decision Transformer to form intrinsic rewards.
                                    </p>
                                </td>
                            </tr>





                        </tbody>
                    </table>


                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td>
                                    <heading>Misc</heading>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table width="100%" align="center" border="0" cellpadding="20">
                        <tbody>

                            <tr>
                                <td width="75%" valign="center">
                                    <strong>Third-Place</strong> in <a href="https://aihabitat.org/challenge/2022_rearrange/">Habitat Rearrangement Challenge 2022</a>
                                </td>
                            </tr>





                        </tbody>
                    </table>
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:0px">
                                    <br>
                                    <p style="text-align:right;font-size:small;">
                                        <a href="https://jonbarron.info/">Template</a>
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                </td>
            </tr>
    </table>
</body>

</html>